{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence-transformers langchain langchain-community langchain-groq langchain-openai spacy yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import yake\n",
    "\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from transformers import pipeline\n",
    "from langchain_openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "from google.colab import userdata\n",
    "os.environ['OPENAI_API_KEY']=userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824c048be9634ac78d8b74d655506973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5056b6500d604c6c99e27367b96c16b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06f6cccd8b04e27810c87016f98868d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3256743c3ec41abaa45e699d94b5973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696580554b91496682a6f380619f2576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d932219fe154ae5a2368ce9d42f0f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd603b7218c049879abbfdb4fad315d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563e53062e014bb5b52855c745b16edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efe602dadbf4434a5a57f634b41a71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24179adc30b64ff89ed884e00f2c078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"en\", n=3, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = \"\"\"\n",
    "Physician: Good morning, Ms. Jones. How are you feeling today?\n",
    "Patient: Good morning, doctor. I’m doing better, but I still have some discomfort now and then.\n",
    "\n",
    "Physician: I understand you were in a car accident last September. Can you walk me through what happened?\n",
    "Patient: Yes, it was on September 1st, around 12:30 in the afternoon. I was driving from Cheadle Hulme to Manchester when I had to stop in traffic. Out of nowhere, another car hit me from behind, which pushed my car into the one in front.\n",
    "\n",
    "Physician: That sounds like a strong impact. Were you wearing your seatbelt?\n",
    "Patient: Yes, I always do.\n",
    "\n",
    "Physician: What did you feel immediately after the accident?\n",
    "Patient: At first, I was just shocked. But then I realized I had hit my head on the steering wheel, and I could feel pain in my neck and back almost right away.\n",
    "\n",
    "Physician: Did you seek medical attention at that time?\n",
    "Patient: Yes, I went to Moss Bank Accident and Emergency. They checked me over and said it was a whiplash injury, but they didn’t do any X-rays. They just gave me some advice and sent me home.\n",
    "\n",
    "Physician: How did things progress after that?\n",
    "Patient: The first four weeks were rough. My neck and back pain were really bad—I had trouble sleeping and had to take painkillers regularly. It started improving after that, but I had to go through ten sessions of physiotherapy to help with the stiffness and discomfort.\n",
    "\n",
    "Physician: That makes sense. Are you still experiencing pain now?\n",
    "Patient: It’s not constant, but I do get occasional backaches. It’s nothing like before, though.\n",
    "\n",
    "Physician: That’s good to hear. Have you noticed any other effects, like anxiety while driving or difficulty concentrating?\n",
    "Patient: No, nothing like that. I don’t feel nervous driving, and I haven’t had any emotional issues from the accident.\n",
    "\n",
    "Physician: And how has this impacted your daily life? Work, hobbies, anything like that?\n",
    "Patient: I had to take a week off work, but after that, I was back to my usual routine. It hasn’t really stopped me from doing anything.\n",
    "\n",
    "Physician: That’s encouraging. Let’s go ahead and do a physical examination to check your mobility and any lingering pain.\n",
    "[Physical Examination Conducted]\n",
    "Physician: Everything looks good. Your neck and back have a full range of movement, and there’s no tenderness or signs of lasting damage. Your muscles and spine seem to be in good condition.\n",
    "\n",
    "Patient: That’s a relief!\n",
    "Physician: Yes, your recovery so far has been quite positive. Given your progress, I’d expect you to make a full recovery within six months of the accident. There are no signs of long-term damage or degeneration.\n",
    "\n",
    "Patient: That’s great to hear. So, I don’t need to worry about this affecting me in the future?\n",
    "Physician: That’s right. I don’t foresee any long-term impact on your work or daily life. If anything changes or you experience worsening symptoms, you can always come back for a follow-up. But at this point, you’re on track for a full recovery.\n",
    "\n",
    "Patient: Thank you, doctor. I appreciate it.\n",
    "Physician: You’re very welcome, Ms. Jones. Take care, and don’t hesitate to reach out if you need anything.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_medical_entities(text):\n",
    "    doc = nlp(text)\n",
    "    out = {\"Symptoms\": [], \"Diagnosis\": [], \"Treatment\": [], \"Prognosis\": []}\n",
    "    patterns = {\n",
    "        \"Symptoms\": [\"neck pain\", \"back pain\", \"headache\", \"stiffness\", \"difficulty sleeping\"],\n",
    "        \"Diagnosis\": [\"whiplash\", \"concussion\"],\n",
    "        \"Treatment\": [\"physiotherapy\", \"painkillers\", \"analgesics\"],\n",
    "        \"Prognosis\": [\"full recovery\", \"no long-term damage\"]\n",
    "    }\n",
    "    lower = text.lower()\n",
    "    for k, pats in patterns.items():\n",
    "        for p in pats:\n",
    "            if p in lower and p not in out[k]:\n",
    "                out[k].append(p.title() if k==\"Symptoms\" else p)\n",
    "\n",
    "    # detect numeric physiotherapy sessions\n",
    "    m = re.findall(r\"(\\d+)\\s+(?:physiotherapy|sessions)\", text, flags=re.I)\n",
    "    for val in m:\n",
    "        out[\"Treatment\"].append(f\"{val} physiotherapy sessions\")\n",
    "\n",
    "    # regex fallback\n",
    "    pain = re.findall(r\"(neck|back|head)[^.,;\\\\n]{0,30}?pain|pain in (?:the )?(neck|back|head)\", text, flags=re.I)\n",
    "    for p in pain:\n",
    "        if isinstance(p, tuple):\n",
    "            part = next((x for x in p if x), None)\n",
    "        else:\n",
    "            part = p\n",
    "        if part:\n",
    "            out[\"Symptoms\"].append(f\"{part.capitalize()} pain\")\n",
    "    for k in out:\n",
    "        out[k] = list(dict.fromkeys(out[k]))\n",
    "    return out\n",
    "NERTool = Tool(\n",
    "    name=\"medical_ner\",\n",
    "    func=lambda text: extract_medical_entities(text),\n",
    "    description=\"Extract Symptoms, Diagnosis, Treatment, Prognosis from transcript\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    words = text.split()\n",
    "    if len(words) > 400:\n",
    "        parts = [\" \".join(words[i:i+400]) for i in range(0, len(words), 400)]\n",
    "        sums = [summarizer(p, max_length=130, min_length=30)[0][\"summary_text\"] for p in parts]\n",
    "        return \" \".join(sums)\n",
    "    return summarizer(text, max_length=150, min_length=30)[0][\"summary_text\"]\n",
    "\n",
    "SummarizerTool = Tool(\n",
    "    name=\"summarizer\",\n",
    "    func=lambda text: summarize_text(text),\n",
    "    description=\"Return a concise medical summary of the transcript\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeywordTool = Tool(\n",
    "    name=\"keywords\",\n",
    "    func=lambda text: [k for k,score in kw_extractor.extract_keywords(text)],\n",
    "    description=\"Extract key medical phrases\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_intent(text):\n",
    "    s = sentiment_pipeline(text)[0]\n",
    "    label = s[\"label\"]\n",
    "    if label.lower() in (\"positive\", \"neutral\"):\n",
    "        sentiment = \"Reassured\"\n",
    "    else:\n",
    "        sentiment = \"Anxious\"\n",
    "    t = text.lower()\n",
    "    if any(w in t for w in [\"worry\", \"worried\", \"concerned\", \"nervous\"]):\n",
    "        intent = \"Seeking reassurance\"\n",
    "    elif any(w in t for w in [\"pain\", \"hurt\", \"ache\", \"stiff\"]):\n",
    "        intent = \"Reporting symptoms\"\n",
    "    else:\n",
    "        intent = \"General\"\n",
    "    return {\"Sentiment\": sentiment, \"Intent\": intent}\n",
    "\n",
    "SentimentTool = Tool(\n",
    "    name=\"sentiment_intent\",\n",
    "    func=lambda text: sentiment_intent(text),\n",
    "    description=\"Return sentiment and intent for patient utterance\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_template = \"\"\"\n",
    "You are a clinical assistant that converts provided notes into a SOAP note JSON.\n",
    "Input:\n",
    "{summary}\n",
    "\n",
    "Entities: {entities}\n",
    "\n",
    "IMPORTANT:\n",
    "- Return ONLY valid JSON. No explanation, no headings, no markdown, no leading text.\n",
    "- Top-level keys must be: \"Subjective\", \"Objective\", \"Assessment\", \"Plan\".\n",
    "- If a field is empty, use an empty string or empty list.\n",
    "\"\"\"\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_entities(ner):\n",
    "    out = {}\n",
    "    for k,v in ner.items():\n",
    "        seen = set()\n",
    "        lst = []\n",
    "        for it in v:\n",
    "            t = \" \".join(it.strip().split())\n",
    "            tnorm = t.lower()\n",
    "            if tnorm not in seen:\n",
    "                lst.append(t.title())\n",
    "                seen.add(tnorm)\n",
    "        out[k] = lst\n",
    "    return out\n",
    "\n",
    "def strip_speakers(text):\n",
    "    lines = []\n",
    "    for line in text.splitlines():\n",
    "        if \":\" in line:\n",
    "            lines.append(line.split(\":\",1)[1].strip())\n",
    "        else:\n",
    "            lines.append(line)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "clean_transcript = strip_speakers(transcript)\n",
    "ner_raw = NERTool.func(clean_transcript)\n",
    "ner = normalize_entities(ner_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY:\n",
      " Ms. Jones suffered a whiplash injury in a car accident last September. She had to go through ten sessions of physiotherapy to help with the stiffness and discomfort. The first four weeks were rough. There are no signs of long-term damage or degeneration. If anything changes, you can always come back for a follow-up. At this point, you’re on track for a full recovery.\n",
      "ENTITIES:\n",
      " {\n",
      "  \"Symptoms\": [\n",
      "    \"Back Pain\",\n",
      "    \"Stiffness\"\n",
      "  ],\n",
      "  \"Diagnosis\": [\n",
      "    \"Whiplash\"\n",
      "  ],\n",
      "  \"Treatment\": [\n",
      "    \"Physiotherapy\",\n",
      "    \"Painkillers\"\n",
      "  ],\n",
      "  \"Prognosis\": [\n",
      "    \"Full Recovery\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "summary_text = summarize_text(clean_transcript)\n",
    "entities_dict = ner\n",
    "print(\"SUMMARY:\\n\", summary_text)\n",
    "print(\"ENTITIES:\\n\", json.dumps(entities_dict, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_prompt = PromptTemplate(input_variables=[\"summary\", \"entities\"], template=soap_template)\n",
    "soap_chain = soap_prompt | llm | JsonOutputParser()\n",
    "soap_inputs = {\n",
    "    \"summary\": summary_text,\n",
    "    \"entities\": json.dumps(entities_dict, ensure_ascii=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_speakers(text):\n",
    "    lines = []\n",
    "    for line in text.splitlines():\n",
    "        lines.append(line.split(\":\",1)[1].strip() if \":\" in line else line)\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_transcript = strip_speakers(transcript)\n",
    "summary_text = SummarizerTool.func(clean_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_first_json(s):\n",
    "    m = re.search(r\"\\{[\\s\\S]*\\}\", s)\n",
    "    return m.group(0) if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0523c92c808e49bc91179a8dad047928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba766f9d762d477690ea43831acf19a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8db26544845495b819ee7eb4b05761e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0daa9d9fe8457bb38358e2a867a962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_fallback = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "\n",
    "def extract_clean_keywords(clean_transcript, KeywordTool, top_n = 10):\n",
    "    raw_kws = KeywordTool.func(clean_transcript)\n",
    "    stopset = {\"physician\", \"patient\", \"good\", \"morning\", \"today\", \"nt\", \"n\"}\n",
    "    def clean_kw(k):\n",
    "        if not k:\n",
    "            return \"\"\n",
    "        # normalize curly quotes, remove punctuation, collapse spaces\n",
    "        k = k.replace(\"’\", \"'\").replace(\"‘\", \"'\")\n",
    "        k = re.sub(r\"[^A-Za-z0-9\\s']\", \" \", k)\n",
    "        k = \" \".join(k.split()).strip()\n",
    "        k = k.replace(\"'\", \"\")\n",
    "        if len(k) <= 2:\n",
    "            return \"\"\n",
    "        return k\n",
    "    keywords = []\n",
    "    for k in raw_kws:\n",
    "        kc = clean_kw(k).lower()\n",
    "        if kc and kc not in stopset and kc not in (x.lower() for x in keywords):\n",
    "            keywords.append(kc.title())\n",
    "        if len(keywords) >= top_n:\n",
    "            break\n",
    "    return keywords\n",
    "\n",
    "sentiment_prompt = PromptTemplate(\n",
    "    input_variables=[\"utterance\"],\n",
    "    template=\"\"\"\n",
    "    You are a clinical NLP assistant. Analyze the patient's statement below:\n",
    "    \"{utterance}\"\n",
    "\n",
    "    Return a JSON:\n",
    "    {\"Sentiment\": one of [\"Anxious\",\"Neutral\",\"Reassured\"],\n",
    "     \"Intent\": one of [\"Reporting symptoms\",\"Seeking reassurance\",\"Expressing gratitude\",\"General\"]}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "sentiment_chain = sentiment_prompt | llm | JsonOutputParser()\n",
    "# sentiment extractor\n",
    "def extract_patient_sentiments_llm(transcript):\n",
    "    patient_utts = [\n",
    "        line.split(\":\", 1)[1].strip()\n",
    "        for line in transcript.splitlines()\n",
    "        if line.strip().lower().startswith(\"patient:\")\n",
    "    ]\n",
    "    sentiments = []\n",
    "    for utt in patient_utts:\n",
    "        try:\n",
    "            s = sentiment_chain.invoke({\"utterance\": utt})\n",
    "            if not isinstance(s, dict):\n",
    "                raise ValueError(\"unexpected sentiment_chain output\")\n",
    "        except Exception:\n",
    "            try:\n",
    "                lbl = sentiment_fallback(utt)[0][\"label\"]\n",
    "                s = {\"Sentiment\": \"Reassured\" if lbl.lower() in (\"positive\",\"neutral\") else \"Anxious\",\n",
    "                     \"Intent\": \"Reporting symptoms\"}\n",
    "            except Exception:\n",
    "                s = {\"Sentiment\": \"Neutral\", \"Intent\": \"General\"}\n",
    "        if not sentiments or s != sentiments[-1]:\n",
    "            sentiments.append(s)\n",
    "    return sentiments\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Sentiment': 'Anxious', 'Intent': 'Reporting symptoms'},\n",
       " {'Sentiment': 'Reassured', 'Intent': 'Reporting symptoms'},\n",
       " {'Sentiment': 'Anxious', 'Intent': 'Reporting symptoms'},\n",
       " {'Sentiment': 'Reassured', 'Intent': 'Reporting symptoms'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_sentiments = extract_patient_sentiments_llm(transcript)\n",
    "patient_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(transcript, patient_name=\"Unknown\"):\n",
    "    patient_sentiments = extract_patient_sentiments_llm(transcript)\n",
    "\n",
    "    # clean transcript for summarizer / keywords / NER\n",
    "    clean_transcript = strip_speakers(transcript)\n",
    "\n",
    "    # NER on cleaned transcript + normalize\n",
    "    ner_raw = NERTool.func(clean_transcript)\n",
    "    ner = normalize_entities(ner_raw)\n",
    "\n",
    "    # Summarize cleaned transcript\n",
    "    summary_text = SummarizerTool.func(clean_transcript)\n",
    "\n",
    "    # Keywords from cleaned transcript\n",
    "    keywords = extract_clean_keywords(clean_transcript, KeywordTool)\n",
    "\n",
    "    # Build SOAP input\n",
    "    entities_json = json.dumps(ner, ensure_ascii=False)\n",
    "    soap_input = {\"summary\": summary_text, \"entities\": entities_json}\n",
    "\n",
    "    # Invoke soap_chain\n",
    "    raw = None\n",
    "    try:\n",
    "        raw = soap_chain.invoke(soap_input)\n",
    "    except Exception:\n",
    "        try:\n",
    "            if hasattr(soap_chain, \"run\"):\n",
    "                raw = soap_chain.run(**soap_input)\n",
    "        except Exception:\n",
    "            prompt_text = soap_prompt.format(summary=summary_text, entities=entities_json)\n",
    "            raw = llm(prompt_text)\n",
    "\n",
    "    print(\"DEBUG SOAP RAW:\", repr(raw))\n",
    "\n",
    "    # normalize into dict\n",
    "    if isinstance(raw, dict):\n",
    "        soap = raw\n",
    "    else:\n",
    "        raw_text = \"\" if raw is None else (raw if isinstance(raw, str) else str(raw))\n",
    "        if raw_text.strip().lower() in (\"\", \"none\"):\n",
    "            soap = {\"raw\": raw_text, \"_validation_missing_keys\": [\"Subjective\",\"Objective\",\"Assessment\",\"Plan\"]}\n",
    "        else:\n",
    "            m = re.search(r\"\\{[\\s\\S]*\\}\", raw_text)\n",
    "            if m:\n",
    "                try:\n",
    "                    soap = json.loads(m.group(0))\n",
    "                except Exception:\n",
    "                    soap = {\"raw\": raw_text}\n",
    "            else:\n",
    "                soap = {\"raw\": raw_text}\n",
    "\n",
    "    # Light non-fatal validation\n",
    "    if isinstance(soap, dict):\n",
    "        missing = [k for k in (\"Subjective\",\"Objective\",\"Assessment\",\"Plan\") if k not in soap]\n",
    "        if missing:\n",
    "            soap[\"_validation_missing_keys\"] = missing\n",
    "\n",
    "    return {\n",
    "        \"Patient_Name\": patient_name,\n",
    "        \"Entities\": ner,\n",
    "        \"Summary\": summary_text,\n",
    "        \"Keywords\": keywords,\n",
    "        \"Patient_Sentiments\": patient_sentiments,\n",
    "        \"SOAP\": soap\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG SOAP RAW: {'Subjective': {'Chief Complaint': 'Ms. Jones suffered a whiplash injury in a car accident last September.', 'History of Present Illness': 'She had to go through ten sessions of physiotherapy to help with the stiffness and discomfort. The first four weeks were rough.'}, 'Objective': {'Symptoms': ['Back Pain', 'Stiffness'], 'Diagnosis': ['Whiplash'], 'Treatment': ['Physiotherapy', 'Painkillers'], 'Prognosis': ['Full Recovery']}, 'Assessment': 'No signs of long-term damage or degeneration. On track for a full recovery.', 'Plan': 'If anything changes, you can always come back for a follow-up.'}\n",
      "{\n",
      "  \"Patient_Name\": \"Janet Jones\",\n",
      "  \"Entities\": {\n",
      "    \"Symptoms\": [\n",
      "      \"Back Pain\",\n",
      "      \"Stiffness\"\n",
      "    ],\n",
      "    \"Diagnosis\": [\n",
      "      \"Whiplash\"\n",
      "    ],\n",
      "    \"Treatment\": [\n",
      "      \"Physiotherapy\",\n",
      "      \"Painkillers\"\n",
      "    ],\n",
      "    \"Prognosis\": [\n",
      "      \"Full Recovery\"\n",
      "    ]\n",
      "  },\n",
      "  \"Summary\": \"Ms. Jones suffered a whiplash injury in a car accident last September. She had to go through ten sessions of physiotherapy to help with the stiffness and discomfort. The first four weeks were rough. There are no signs of long-term damage or degeneration. If anything changes, you can always come back for a follow-up. At this point, you\\u2019re on track for a full recovery.\",\n",
      "  \"Keywords\": [\n",
      "    \"Accident\",\n",
      "    \"Back\",\n",
      "    \"Good Morning\",\n",
      "    \"Pain\",\n",
      "    \"September\",\n",
      "    \"Moss Bank Accident\",\n",
      "    \"Car\"\n",
      "  ],\n",
      "  \"Patient_Sentiments\": [\n",
      "    {\n",
      "      \"Sentiment\": \"Anxious\",\n",
      "      \"Intent\": \"Reporting symptoms\"\n",
      "    },\n",
      "    {\n",
      "      \"Sentiment\": \"Reassured\",\n",
      "      \"Intent\": \"Reporting symptoms\"\n",
      "    },\n",
      "    {\n",
      "      \"Sentiment\": \"Anxious\",\n",
      "      \"Intent\": \"Reporting symptoms\"\n",
      "    },\n",
      "    {\n",
      "      \"Sentiment\": \"Reassured\",\n",
      "      \"Intent\": \"Reporting symptoms\"\n",
      "    }\n",
      "  ],\n",
      "  \"SOAP\": {\n",
      "    \"Subjective\": {\n",
      "      \"Chief Complaint\": \"Ms. Jones suffered a whiplash injury in a car accident last September.\",\n",
      "      \"History of Present Illness\": \"She had to go through ten sessions of physiotherapy to help with the stiffness and discomfort. The first four weeks were rough.\"\n",
      "    },\n",
      "    \"Objective\": {\n",
      "      \"Symptoms\": [\n",
      "        \"Back Pain\",\n",
      "        \"Stiffness\"\n",
      "      ],\n",
      "      \"Diagnosis\": [\n",
      "        \"Whiplash\"\n",
      "      ],\n",
      "      \"Treatment\": [\n",
      "        \"Physiotherapy\",\n",
      "        \"Painkillers\"\n",
      "      ],\n",
      "      \"Prognosis\": [\n",
      "        \"Full Recovery\"\n",
      "      ]\n",
      "    },\n",
      "    \"Assessment\": \"No signs of long-term damage or degeneration. On track for a full recovery.\",\n",
      "    \"Plan\": \"If anything changes, you can always come back for a follow-up.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "out = run_pipeline(transcript, patient_name=\"Janet Jones\")\n",
    "print(json.dumps(out, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
